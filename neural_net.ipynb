{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6499e272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from dataloader_multimodal import VideoDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ebaa2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuralSkillClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "\n",
    "        # inicia um backbone da rede com a ResNet18 pré-treinada\n",
    "        self.backbone = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "\n",
    "        # modifica a primeira camada para receber apenas 1 canal de entrada\n",
    "        self.backbone.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        \n",
    "        # remove a camada de classificação original da ResNet, substituindo-a por uma nn.Identity()\n",
    "        self.backbone.fc = nn.Identity()\n",
    "\n",
    "        # cria uma nova camada de classificação, conforme descrita no artigo, com 512 valores de entrada e 128 de saída,\n",
    "        # posteriormente passando por uma camada que faz a classificação de fato, com 10 valores de saída (correspondentes às classes)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=512, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5)\n",
    "        )\n",
    "        self.classification_head = nn.Linear(128, num_classes)\n",
    "        self.regression_head = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x) # passa a entrada pela rede ResNet\n",
    "        features_128 = self.classifier(features) # passa o resultado da ResNet pela camada final de classificação\n",
    "        logits_cls = self.classification_head(features_128)\n",
    "        output_reg = self.regression_head(features_128)\n",
    "\n",
    "        return logits_cls, output_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5c79045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando o dispositivo: cuda\n",
      "Formato do tensor de entrada: torch.Size([4, 1, 224, 224])\n",
      "Formato do tensor de saída: torch.Size([4, 10]), torch.Size([4, 1])\n",
      "Tensor de saída (logits):\n",
      "(tensor([[ 0.0240,  0.1101,  0.2270,  0.3069,  0.0485,  0.0774, -0.1472,  0.3770,\n",
      "         -0.1193,  0.0270],\n",
      "        [ 0.0271,  0.1411,  0.2155,  0.3088,  0.0610,  0.0791, -0.1510,  0.3970,\n",
      "         -0.1299,  0.0367],\n",
      "        [ 0.0285,  0.1314,  0.2266,  0.3071,  0.0486,  0.0897, -0.1352,  0.3748,\n",
      "         -0.1330,  0.0397],\n",
      "        [ 0.0255,  0.1292,  0.2180,  0.3128,  0.0572,  0.0897, -0.1448,  0.3905,\n",
      "         -0.1271,  0.0361]], device='cuda:0'), tensor([[0.0479],\n",
      "        [0.0481],\n",
      "        [0.0583],\n",
      "        [0.0589]], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Usando o dispositivo: {device}\")\n",
    "\n",
    "# 2. Crie uma instância do seu modelo e mova para o dispositivo\n",
    "model = AuralSkillClassifier(num_classes=10).to(device)\n",
    "\n",
    "# Coloca o modelo em modo de avaliação (importante para desativar o Dropout)\n",
    "model.eval()\n",
    "\n",
    "# 3. Crie um lote de dados \"falsos\" (dummy tensor)\n",
    "# Formato: [batch_size, channels, height, width]\n",
    "# batch_size = 4 (simulando 4 imagens de uma vez)\n",
    "# channels = 1 (seu espectrograma é escala de cinza)\n",
    "# height = 224\n",
    "# width = 224\n",
    "batch_size = 4\n",
    "dummy_input = torch.rand(batch_size, 1, 224, 224).to(device)\n",
    "\n",
    "print(f\"Formato do tensor de entrada: {dummy_input.shape}\")\n",
    "\n",
    "# 4. Passe os dados falsos pelo modelo\n",
    "# torch.no_grad() desliga o cálculo de gradientes, o que torna\n",
    "# a inferência mais rápida e economiza memória.\n",
    "with torch.no_grad():\n",
    "    output = model(dummy_input)\n",
    "\n",
    "# 5. Verifique a saída\n",
    "print(f\"Formato do tensor de saída: {output[0].shape}, {output[1].shape}\")\n",
    "print(\"Tensor de saída (logits):\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2b92c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_cls = nn.CrossEntropyLoss()\n",
    "criterion_reg_l1 = nn.L1Loss()\n",
    "criterion_reg_l2 = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "902a294c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eda96cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = VideoDataset(mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f618eb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie o DataLoader (você já deve ter feito isso em um passo anterior)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "961b81ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opts import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59847007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando Época 1/10 ---\n",
      "  Processando lote 1/129\n",
      "  Processando lote 2/129\n",
      "  Processando lote 3/129\n",
      "  Processando lote 4/129\n",
      "  Processando lote 5/129\n",
      "  Processando lote 6/129\n",
      "  Processando lote 7/129\n",
      "  Processando lote 8/129\n",
      "  Processando lote 9/129\n",
      "  Processando lote 10/129\n",
      "  Processando lote 11/129\n",
      "  Processando lote 12/129\n",
      "  Processando lote 13/129\n",
      "  Processando lote 14/129\n",
      "  Processando lote 15/129\n",
      "  Processando lote 16/129\n",
      "  Processando lote 17/129\n",
      "  Processando lote 18/129\n",
      "  Processando lote 19/129\n",
      "  Processando lote 20/129\n",
      "  Processando lote 21/129\n",
      "  Processando lote 22/129\n",
      "  Processando lote 23/129\n",
      "  Processando lote 24/129\n",
      "  Processando lote 25/129\n",
      "  Processando lote 26/129\n",
      "  Processando lote 27/129\n",
      "  Processando lote 28/129\n",
      "  Processando lote 29/129\n",
      "  Processando lote 30/129\n",
      "  Processando lote 31/129\n",
      "  Processando lote 32/129\n",
      "  Processando lote 33/129\n",
      "  Processando lote 34/129\n",
      "  Processando lote 35/129\n",
      "  Processando lote 36/129\n",
      "  Processando lote 37/129\n",
      "  Processando lote 38/129\n",
      "  Processando lote 39/129\n",
      "  Processando lote 40/129\n",
      "  Processando lote 41/129\n",
      "  Processando lote 42/129\n",
      "  Processando lote 43/129\n",
      "  Processando lote 44/129\n",
      "  Processando lote 45/129\n",
      "  Processando lote 46/129\n",
      "  Processando lote 47/129\n",
      "  Processando lote 48/129\n",
      "  Processando lote 49/129\n",
      "  Processando lote 50/129\n",
      "  Processando lote 51/129\n",
      "  Processando lote 52/129\n",
      "  Processando lote 53/129\n",
      "  Processando lote 54/129\n",
      "  Processando lote 55/129\n",
      "  Processando lote 56/129\n",
      "  Processando lote 57/129\n",
      "  Processando lote 58/129\n",
      "  Processando lote 59/129\n",
      "  Processando lote 60/129\n",
      "  Processando lote 61/129\n",
      "  Processando lote 62/129\n",
      "  Processando lote 63/129\n",
      "  Processando lote 64/129\n",
      "  Processando lote 65/129\n",
      "  Processando lote 66/129\n",
      "  Processando lote 67/129\n",
      "  Processando lote 68/129\n",
      "  Processando lote 69/129\n",
      "  Processando lote 70/129\n",
      "  Processando lote 71/129\n",
      "  Processando lote 72/129\n",
      "  Processando lote 73/129\n",
      "  Processando lote 74/129\n",
      "  Processando lote 75/129\n",
      "  Processando lote 76/129\n",
      "  Processando lote 77/129\n",
      "  Processando lote 78/129\n",
      "  Processando lote 79/129\n",
      "  Processando lote 80/129\n",
      "  Processando lote 81/129\n",
      "  Processando lote 82/129\n",
      "  Processando lote 83/129\n",
      "  Processando lote 84/129\n",
      "  Processando lote 85/129\n",
      "  Processando lote 86/129\n",
      "  Processando lote 87/129\n",
      "  Processando lote 88/129\n",
      "  Processando lote 89/129\n",
      "  Processando lote 90/129\n",
      "  Processando lote 91/129\n",
      "  Processando lote 92/129\n",
      "  Processando lote 93/129\n",
      "  Processando lote 94/129\n",
      "  Processando lote 95/129\n",
      "  Processando lote 96/129\n",
      "  Processando lote 97/129\n",
      "  Processando lote 98/129\n",
      "  Processando lote 99/129\n",
      "  Processando lote 100/129\n",
      "  Processando lote 101/129\n",
      "  Processando lote 102/129\n",
      "  Processando lote 103/129\n",
      "  Processando lote 104/129\n",
      "  Processando lote 105/129\n",
      "  Processando lote 106/129\n",
      "  Processando lote 107/129\n",
      "  Processando lote 108/129\n",
      "  Processando lote 109/129\n",
      "  Processando lote 110/129\n",
      "  Processando lote 111/129\n",
      "  Processando lote 112/129\n",
      "  Processando lote 113/129\n",
      "  Processando lote 114/129\n",
      "  Processando lote 115/129\n",
      "  Processando lote 116/129\n",
      "  Processando lote 117/129\n",
      "  Processando lote 118/129\n",
      "  Processando lote 119/129\n",
      "  Processando lote 120/129\n",
      "  Processando lote 121/129\n",
      "  Processando lote 122/129\n",
      "  Processando lote 123/129\n",
      "  Processando lote 124/129\n",
      "  Processando lote 125/129\n",
      "  Processando lote 126/129\n",
      "  Processando lote 127/129\n",
      "  Processando lote 128/129\n",
      "  Processando lote 129/129\n",
      "--- Época 1 concluída ---\n",
      "--- Iniciando Época 2/10 ---\n",
      "  Processando lote 1/129\n",
      "  Processando lote 2/129\n",
      "  Processando lote 3/129\n",
      "  Processando lote 4/129\n",
      "  Processando lote 5/129\n",
      "  Processando lote 6/129\n",
      "  Processando lote 7/129\n",
      "  Processando lote 8/129\n",
      "  Processando lote 9/129\n",
      "  Processando lote 10/129\n",
      "  Processando lote 11/129\n",
      "  Processando lote 12/129\n",
      "  Processando lote 13/129\n",
      "  Processando lote 14/129\n",
      "  Processando lote 15/129\n",
      "  Processando lote 16/129\n",
      "  Processando lote 17/129\n",
      "  Processando lote 18/129\n",
      "  Processando lote 19/129\n",
      "  Processando lote 20/129\n",
      "  Processando lote 21/129\n",
      "  Processando lote 22/129\n",
      "  Processando lote 23/129\n",
      "  Processando lote 24/129\n",
      "  Processando lote 25/129\n",
      "  Processando lote 26/129\n",
      "  Processando lote 27/129\n",
      "  Processando lote 28/129\n",
      "  Processando lote 29/129\n",
      "  Processando lote 30/129\n",
      "  Processando lote 31/129\n",
      "  Processando lote 32/129\n",
      "  Processando lote 33/129\n",
      "  Processando lote 34/129\n",
      "  Processando lote 35/129\n",
      "  Processando lote 36/129\n",
      "  Processando lote 37/129\n",
      "  Processando lote 38/129\n",
      "  Processando lote 39/129\n",
      "  Processando lote 40/129\n",
      "  Processando lote 41/129\n",
      "  Processando lote 42/129\n",
      "  Processando lote 43/129\n",
      "  Processando lote 44/129\n",
      "  Processando lote 45/129\n",
      "  Processando lote 46/129\n",
      "  Processando lote 47/129\n",
      "  Processando lote 48/129\n",
      "  Processando lote 49/129\n",
      "  Processando lote 50/129\n",
      "  Processando lote 51/129\n",
      "  Processando lote 52/129\n",
      "  Processando lote 53/129\n",
      "  Processando lote 54/129\n",
      "  Processando lote 55/129\n",
      "  Processando lote 56/129\n",
      "  Processando lote 57/129\n",
      "  Processando lote 58/129\n",
      "  Processando lote 59/129\n",
      "  Processando lote 60/129\n",
      "  Processando lote 61/129\n",
      "  Processando lote 62/129\n",
      "  Processando lote 63/129\n",
      "  Processando lote 64/129\n",
      "  Processando lote 65/129\n",
      "  Processando lote 66/129\n",
      "  Processando lote 67/129\n",
      "  Processando lote 68/129\n",
      "  Processando lote 69/129\n",
      "  Processando lote 70/129\n",
      "  Processando lote 71/129\n",
      "  Processando lote 72/129\n",
      "  Processando lote 73/129\n",
      "  Processando lote 74/129\n",
      "  Processando lote 75/129\n",
      "  Processando lote 76/129\n",
      "  Processando lote 77/129\n",
      "  Processando lote 78/129\n",
      "  Processando lote 79/129\n",
      "  Processando lote 80/129\n",
      "  Processando lote 81/129\n",
      "  Processando lote 82/129\n",
      "  Processando lote 83/129\n",
      "  Processando lote 84/129\n",
      "  Processando lote 85/129\n",
      "  Processando lote 86/129\n",
      "  Processando lote 87/129\n",
      "  Processando lote 88/129\n",
      "  Processando lote 89/129\n",
      "  Processando lote 90/129\n",
      "  Processando lote 91/129\n",
      "  Processando lote 92/129\n",
      "  Processando lote 93/129\n",
      "  Processando lote 94/129\n",
      "  Processando lote 95/129\n",
      "  Processando lote 96/129\n",
      "  Processando lote 97/129\n",
      "  Processando lote 98/129\n",
      "  Processando lote 99/129\n",
      "  Processando lote 100/129\n",
      "  Processando lote 101/129\n",
      "  Processando lote 102/129\n",
      "  Processando lote 103/129\n",
      "  Processando lote 104/129\n",
      "  Processando lote 105/129\n",
      "  Processando lote 106/129\n",
      "  Processando lote 107/129\n",
      "  Processando lote 108/129\n",
      "  Processando lote 109/129\n",
      "  Processando lote 110/129\n",
      "  Processando lote 111/129\n",
      "  Processando lote 112/129\n",
      "  Processando lote 113/129\n",
      "  Processando lote 114/129\n",
      "  Processando lote 115/129\n",
      "  Processando lote 116/129\n",
      "  Processando lote 117/129\n",
      "  Processando lote 118/129\n",
      "  Processando lote 119/129\n",
      "  Processando lote 120/129\n",
      "  Processando lote 121/129\n",
      "  Processando lote 122/129\n",
      "  Processando lote 123/129\n",
      "  Processando lote 124/129\n",
      "  Processando lote 125/129\n",
      "  Processando lote 126/129\n",
      "  Processando lote 127/129\n",
      "  Processando lote 128/129\n",
      "  Processando lote 129/129\n",
      "--- Época 2 concluída ---\n",
      "--- Iniciando Época 3/10 ---\n",
      "  Processando lote 1/129\n",
      "  Processando lote 2/129\n",
      "  Processando lote 3/129\n",
      "  Processando lote 4/129\n",
      "  Processando lote 5/129\n",
      "  Processando lote 6/129\n",
      "  Processando lote 7/129\n",
      "  Processando lote 8/129\n",
      "  Processando lote 9/129\n",
      "  Processando lote 10/129\n",
      "  Processando lote 11/129\n",
      "  Processando lote 12/129\n",
      "  Processando lote 13/129\n",
      "  Processando lote 14/129\n",
      "  Processando lote 15/129\n",
      "  Processando lote 16/129\n",
      "  Processando lote 17/129\n",
      "  Processando lote 18/129\n",
      "  Processando lote 19/129\n",
      "  Processando lote 20/129\n",
      "  Processando lote 21/129\n",
      "  Processando lote 22/129\n",
      "  Processando lote 23/129\n",
      "  Processando lote 24/129\n",
      "  Processando lote 25/129\n",
      "  Processando lote 26/129\n",
      "  Processando lote 27/129\n",
      "  Processando lote 28/129\n",
      "  Processando lote 29/129\n",
      "  Processando lote 30/129\n",
      "  Processando lote 31/129\n",
      "  Processando lote 32/129\n",
      "  Processando lote 33/129\n",
      "  Processando lote 34/129\n",
      "  Processando lote 35/129\n",
      "  Processando lote 36/129\n",
      "  Processando lote 37/129\n",
      "  Processando lote 38/129\n",
      "  Processando lote 39/129\n",
      "  Processando lote 40/129\n",
      "  Processando lote 41/129\n",
      "  Processando lote 42/129\n",
      "  Processando lote 43/129\n",
      "  Processando lote 44/129\n",
      "  Processando lote 45/129\n",
      "  Processando lote 46/129\n",
      "  Processando lote 47/129\n",
      "  Processando lote 48/129\n",
      "  Processando lote 49/129\n",
      "  Processando lote 50/129\n",
      "  Processando lote 51/129\n",
      "  Processando lote 52/129\n",
      "  Processando lote 53/129\n",
      "  Processando lote 54/129\n",
      "  Processando lote 55/129\n",
      "  Processando lote 56/129\n",
      "  Processando lote 57/129\n",
      "  Processando lote 58/129\n",
      "  Processando lote 59/129\n",
      "  Processando lote 60/129\n",
      "  Processando lote 61/129\n",
      "  Processando lote 62/129\n",
      "  Processando lote 63/129\n",
      "  Processando lote 64/129\n",
      "  Processando lote 65/129\n",
      "  Processando lote 66/129\n",
      "  Processando lote 67/129\n",
      "  Processando lote 68/129\n",
      "  Processando lote 69/129\n",
      "  Processando lote 70/129\n",
      "  Processando lote 71/129\n",
      "  Processando lote 72/129\n",
      "  Processando lote 73/129\n",
      "  Processando lote 74/129\n",
      "  Processando lote 75/129\n",
      "  Processando lote 76/129\n",
      "  Processando lote 77/129\n",
      "  Processando lote 78/129\n",
      "  Processando lote 79/129\n",
      "  Processando lote 80/129\n",
      "  Processando lote 81/129\n",
      "  Processando lote 82/129\n",
      "  Processando lote 83/129\n",
      "  Processando lote 84/129\n",
      "  Processando lote 85/129\n",
      "  Processando lote 86/129\n",
      "  Processando lote 87/129\n",
      "  Processando lote 88/129\n",
      "  Processando lote 89/129\n",
      "  Processando lote 90/129\n",
      "  Processando lote 91/129\n",
      "  Processando lote 92/129\n",
      "  Processando lote 93/129\n",
      "  Processando lote 94/129\n",
      "  Processando lote 95/129\n",
      "  Processando lote 96/129\n",
      "  Processando lote 97/129\n",
      "  Processando lote 98/129\n",
      "  Processando lote 99/129\n",
      "  Processando lote 100/129\n",
      "  Processando lote 101/129\n",
      "  Processando lote 102/129\n",
      "  Processando lote 103/129\n",
      "  Processando lote 104/129\n",
      "  Processando lote 105/129\n",
      "  Processando lote 106/129\n",
      "  Processando lote 107/129\n",
      "  Processando lote 108/129\n",
      "  Processando lote 109/129\n",
      "  Processando lote 110/129\n",
      "  Processando lote 111/129\n",
      "  Processando lote 112/129\n",
      "  Processando lote 113/129\n",
      "  Processando lote 114/129\n",
      "  Processando lote 115/129\n",
      "  Processando lote 116/129\n",
      "  Processando lote 117/129\n",
      "  Processando lote 118/129\n",
      "  Processando lote 119/129\n",
      "  Processando lote 120/129\n",
      "  Processando lote 121/129\n",
      "  Processando lote 122/129\n",
      "  Processando lote 123/129\n",
      "  Processando lote 124/129\n",
      "  Processando lote 125/129\n",
      "  Processando lote 126/129\n",
      "  Processando lote 127/129\n",
      "  Processando lote 128/129\n",
      "  Processando lote 129/129\n",
      "--- Época 3 concluída ---\n",
      "--- Iniciando Época 4/10 ---\n",
      "  Processando lote 1/129\n",
      "  Processando lote 2/129\n",
      "  Processando lote 3/129\n",
      "  Processando lote 4/129\n",
      "  Processando lote 5/129\n",
      "  Processando lote 6/129\n",
      "  Processando lote 7/129\n",
      "  Processando lote 8/129\n",
      "  Processando lote 9/129\n",
      "  Processando lote 10/129\n",
      "  Processando lote 11/129\n",
      "  Processando lote 12/129\n",
      "  Processando lote 13/129\n",
      "  Processando lote 14/129\n",
      "  Processando lote 15/129\n",
      "  Processando lote 16/129\n",
      "  Processando lote 17/129\n",
      "  Processando lote 18/129\n",
      "  Processando lote 19/129\n",
      "  Processando lote 20/129\n",
      "  Processando lote 21/129\n",
      "  Processando lote 22/129\n",
      "  Processando lote 23/129\n",
      "  Processando lote 24/129\n",
      "  Processando lote 25/129\n",
      "  Processando lote 26/129\n",
      "  Processando lote 27/129\n",
      "  Processando lote 28/129\n",
      "  Processando lote 29/129\n",
      "  Processando lote 30/129\n",
      "  Processando lote 31/129\n",
      "  Processando lote 32/129\n",
      "  Processando lote 33/129\n",
      "  Processando lote 34/129\n",
      "  Processando lote 35/129\n",
      "  Processando lote 36/129\n",
      "  Processando lote 37/129\n",
      "  Processando lote 38/129\n",
      "  Processando lote 39/129\n",
      "  Processando lote 40/129\n",
      "  Processando lote 41/129\n",
      "  Processando lote 42/129\n",
      "  Processando lote 43/129\n",
      "  Processando lote 44/129\n",
      "  Processando lote 45/129\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     43\u001b[39m     loss_reg = l1 + l2\n\u001b[32m     44\u001b[39m     loss = (\u001b[32m1.0\u001b[39m * loss_cls) + (\u001b[32m0.1\u001b[39m * loss_reg)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m     optimizer.step()\n\u001b[32m     47\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m--- Época \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m concluída ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\autograd\\__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\autograd\\graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"--- Iniciando Época {epoch+1}/{num_epochs} ---\")\n",
    "    # para cada lote de dados:\n",
    "    # pegar o tensor 5D de espectrogramas\n",
    "\n",
    "    # criar listas vazias para guardar as saídas\n",
    "\n",
    "    # para cada um dos 10 clipes:\n",
    "    # fatiar o tensor 5D para pegar o clipe atual (que será 4D)\n",
    "    # passar o clipe 4D pelo modelo\n",
    "    # guardar as duas saídas (cls e reg) nas listas\n",
    "\n",
    "    # agregar os resultados das listas (ex: empilhar e tirar a média)\n",
    "\n",
    "    # usar as saídas médias para calcular a perda total (cls + reg)\n",
    "\n",
    "    # fazer loss.backward()\n",
    "    # fazer optimizer.step()\n",
    "    for i, batch_data in enumerate(train_loader):\n",
    "        print(f\"  Processando lote {i+1}/{len(train_loader)}\")\n",
    "        optimizer.zero_grad()\n",
    "        spectrograms_tensor = batch_data['audio'].to(device)\n",
    "        labels = batch_data['player_lvl'].to(device)\n",
    "        lista_outputs_cls = []\n",
    "        lista_outputs_reg = []\n",
    "        labels_long = labels.long()\n",
    "        labels_float = labels.float()\n",
    "\n",
    "        for i in range(nclips):\n",
    "            clip_tensor = spectrograms_tensor[:, i, :, :, :]\n",
    "            logits_cls_clip, output_reg_clip = model(clip_tensor)\n",
    "            lista_outputs_cls.append(logits_cls_clip)\n",
    "            lista_outputs_reg.append(output_reg_clip)\n",
    "        logits_cls = (torch.stack(lista_outputs_cls)).mean(dim=0)\n",
    "        output_reg = (torch.stack(lista_outputs_reg)).mean(dim=0)\n",
    "        \n",
    "        loss_cls = criterion_cls(logits_cls, labels_long)\n",
    "\n",
    "        output_reg = output_reg.squeeze()\n",
    "        l1 = criterion_reg_l1(output_reg, labels_float)\n",
    "        l2 = criterion_reg_l2(output_reg, labels_float)\n",
    "        loss_reg = l1 + l2\n",
    "        loss = (1.0 * loss_cls) + (0.1 * loss_reg)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"--- Época {epoch+1} concluída ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f0eb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Bloco de Código para Visualização ---\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Supondo que você já tenha criado seu 'train_dataset' assim:\n",
    "# train_dataset = VideoDataset(mode='train')\n",
    "\n",
    "print(\"Carregando uma amostra do dataset para visualização...\")\n",
    "\n",
    "# 1. Pegue uma amostra do dataset (aqui, pegamos a primeira, índice 0)\n",
    "# O __getitem__ do seu dataset será chamado e retornará o dicionário de dados.\n",
    "sample_data = train_dataset[0]\n",
    "\n",
    "# 2. Extraia o tensor dos espectrogramas e a etiqueta (label)\n",
    "# Lembre-se que 'audio' é um tensor com shape [nclips, C, H, W], ou seja, [10, 1, 224, 224]\n",
    "spectrograms_tensor = sample_data['audio']\n",
    "label = sample_data['player_lvl']\n",
    "\n",
    "print(f\"Formato do tensor de áudio da amostra: {spectrograms_tensor.shape}\")\n",
    "print(f\"Nível de Habilidade (Label): {label}\")\n",
    "\n",
    "# 3. Escolha um dos 10 clipes para visualizar (vamos pegar o primeiro, índice 0)\n",
    "first_clip_tensor = spectrograms_tensor[0]\n",
    "\n",
    "# 4. Prepare o tensor para ser plotado com matplotlib\n",
    "#    - .squeeze() remove dimensões de tamanho 1. Transforma [1, 224, 224] em [224, 224].\n",
    "#    - .cpu() garante que o tensor está na CPU, pois matplotlib não funciona com tensores na GPU.\n",
    "#    - .numpy() converte o tensor do PyTorch para um array do NumPy, que é o formato que o matplotlib espera.\n",
    "image_to_show = first_clip_tensor.squeeze().cpu().numpy()\n",
    "\n",
    "# 5. Plote a imagem\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(f\"Espectrograma do Clipe 0 | Nível de Habilidade: {label}\")\n",
    "plt.xlabel(\"Tempo (esticado para 224 pixels)\")\n",
    "plt.ylabel(\"Frequência (esticada para 224 pixels)\")\n",
    "# cmap='gray' garante que a imagem seja exibida em escala de cinza\n",
    "plt.imshow(image_to_show, cmap='gray', origin='lower') \n",
    "plt.colorbar(label='Intensidade (normalizada)') # Adiciona uma barra de cores para indicar a intensidade\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
