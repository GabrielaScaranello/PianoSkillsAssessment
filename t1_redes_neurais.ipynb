{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z16QotNMDt9E",
        "outputId": "c65b8355-1b75-4853-ff63-17408eb684f0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=169RiUEtrp4cD1zN-AjEWvSUyGOAcDgXb\n",
            "From (redirected): https://drive.google.com/uc?id=169RiUEtrp4cD1zN-AjEWvSUyGOAcDgXb&confirm=t&uuid=fd8eed84-9b56-4f9f-b289-67dd76bfaa9f\n",
            "To: c:\\Users\\luqui\\OneDrive\\lvcas\\USP\\7o Período\\Redes Neurais\\trabalho\\PianoSkillsAssessment\\processed_data.zip\n",
            "\n",
            "  0%|          | 0.00/327M [00:00<?, ?B/s]\n",
            "  0%|          | 524k/327M [00:00<02:29, 2.19MB/s]\n",
            "  1%|          | 2.62M/327M [00:00<00:37, 8.64MB/s]\n",
            "  3%|▎         | 8.39M/327M [00:00<00:13, 24.3MB/s]\n",
            "  4%|▍         | 14.7M/327M [00:00<00:08, 35.6MB/s]\n",
            "  6%|▋         | 21.0M/327M [00:00<00:07, 42.8MB/s]\n",
            "  8%|▊         | 27.3M/327M [00:00<00:06, 48.6MB/s]\n",
            " 11%|█         | 36.7M/327M [00:00<00:04, 61.3MB/s]\n",
            " 14%|█▎        | 44.6M/327M [00:00<00:04, 65.9MB/s]\n",
            " 16%|█▌        | 52.4M/327M [00:01<00:04, 67.5MB/s]\n",
            " 18%|█▊        | 60.3M/327M [00:01<00:03, 70.1MB/s]\n",
            " 21%|██        | 68.2M/327M [00:01<00:03, 72.1MB/s]\n",
            " 23%|██▎       | 75.5M/327M [00:01<00:03, 66.1MB/s]\n",
            " 25%|██▌       | 83.4M/327M [00:01<00:03, 69.2MB/s]\n",
            " 28%|██▊       | 91.2M/327M [00:01<00:03, 71.0MB/s]\n",
            " 30%|███       | 98.6M/327M [00:01<00:03, 70.6MB/s]\n",
            " 33%|███▎      | 106M/327M [00:01<00:03, 72.7MB/s] \n",
            " 35%|███▍      | 114M/327M [00:01<00:02, 71.7MB/s]\n",
            " 37%|███▋      | 121M/327M [00:02<00:02, 70.9MB/s]\n",
            " 39%|███▉      | 129M/327M [00:02<00:02, 72.1MB/s]\n",
            " 42%|████▏     | 137M/327M [00:02<00:02, 73.2MB/s]\n",
            " 44%|████▍     | 145M/327M [00:02<00:02, 73.6MB/s]\n",
            " 47%|████▋     | 153M/327M [00:02<00:02, 70.6MB/s]\n",
            " 49%|████▉     | 160M/327M [00:02<00:02, 72.0MB/s]\n",
            " 51%|█████▏    | 168M/327M [00:02<00:02, 71.9MB/s]\n",
            " 54%|█████▎    | 176M/327M [00:02<00:02, 73.2MB/s]\n",
            " 56%|█████▌    | 184M/327M [00:02<00:01, 74.0MB/s]\n",
            " 59%|█████▊    | 191M/327M [00:03<00:01, 74.5MB/s]\n",
            " 61%|██████    | 199M/327M [00:03<00:01, 74.5MB/s]\n",
            " 63%|██████▎   | 207M/327M [00:03<00:01, 74.9MB/s]\n",
            " 66%|██████▌   | 215M/327M [00:03<00:01, 75.5MB/s]\n",
            " 68%|██████▊   | 223M/327M [00:03<00:01, 74.6MB/s]\n",
            " 71%|███████   | 231M/327M [00:03<00:01, 68.8MB/s]\n",
            " 73%|███████▎  | 238M/327M [00:03<00:01, 60.3MB/s]\n",
            " 75%|███████▍  | 244M/327M [00:03<00:01, 60.2MB/s]\n",
            " 77%|███████▋  | 252M/327M [00:03<00:01, 64.6MB/s]\n",
            " 80%|███████▉  | 260M/327M [00:04<00:00, 67.2MB/s]\n",
            " 82%|████████▏ | 267M/327M [00:04<00:00, 68.8MB/s]\n",
            " 84%|████████▍ | 275M/327M [00:04<00:00, 70.9MB/s]\n",
            " 87%|████████▋ | 283M/327M [00:04<00:00, 72.6MB/s]\n",
            " 89%|████████▉ | 291M/327M [00:04<00:00, 73.9MB/s]\n",
            " 91%|█████████▏| 299M/327M [00:04<00:00, 73.8MB/s]\n",
            " 94%|█████████▍| 307M/327M [00:04<00:00, 73.7MB/s]\n",
            " 96%|█████████▌| 315M/327M [00:04<00:00, 69.5MB/s]\n",
            " 99%|█████████▊| 322M/327M [00:04<00:00, 71.6MB/s]\n",
            "100%|██████████| 327M/327M [00:04<00:00, 66.0MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1Be4s_PFa2Uyc67iOqAEyMc_Ce5WiJ_fH\n",
            "From (redirected): https://drive.google.com/uc?id=1Be4s_PFa2Uyc67iOqAEyMc_Ce5WiJ_fH&confirm=t&uuid=747594ac-6943-4fb9-a549-29e740b6c59d\n",
            "To: c:\\Users\\luqui\\OneDrive\\lvcas\\USP\\7o Período\\Redes Neurais\\trabalho\\PianoSkillsAssessment\\checkpoints_batch4.zip\n",
            "\n",
            "  0%|          | 0.00/124M [00:00<?, ?B/s]\n",
            "  0%|          | 524k/124M [00:00<00:58, 2.10MB/s]\n",
            "  2%|▏         | 2.10M/124M [00:00<00:18, 6.78MB/s]\n",
            "  6%|▋         | 7.86M/124M [00:00<00:04, 23.5MB/s]\n",
            " 12%|█▏        | 15.2M/124M [00:00<00:02, 39.5MB/s]\n",
            " 18%|█▊        | 22.5M/124M [00:00<00:02, 50.1MB/s]\n",
            " 24%|██▍       | 30.4M/124M [00:00<00:01, 58.7MB/s]\n",
            " 31%|███       | 38.3M/124M [00:00<00:01, 64.1MB/s]\n",
            " 36%|███▌      | 45.1M/124M [00:00<00:01, 64.2MB/s]\n",
            " 43%|████▎     | 53.0M/124M [00:01<00:01, 67.7MB/s]\n",
            " 48%|████▊     | 60.3M/124M [00:01<00:00, 69.1MB/s]\n",
            " 54%|█████▍    | 67.6M/124M [00:01<00:00, 67.3MB/s]\n",
            " 62%|██████▏   | 76.5M/124M [00:01<00:00, 73.5MB/s]\n",
            " 68%|██████▊   | 84.4M/124M [00:01<00:00, 74.7MB/s]\n",
            " 74%|███████▍  | 92.3M/124M [00:01<00:00, 75.1MB/s]\n",
            " 80%|████████  | 100M/124M [00:01<00:00, 75.2MB/s] \n",
            " 87%|████████▋ | 108M/124M [00:01<00:00, 75.2MB/s]\n",
            " 93%|█████████▎| 116M/124M [00:01<00:00, 75.4MB/s]\n",
            " 99%|█████████▉| 124M/124M [00:02<00:00, 73.5MB/s]\n",
            "100%|██████████| 124M/124M [00:02<00:00, 61.3MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1fc6DWa9hnxYtRhuHntdXllPrrVQ54NiH\n",
            "From (redirected): https://drive.google.com/uc?id=1fc6DWa9hnxYtRhuHntdXllPrrVQ54NiH&confirm=t&uuid=87279abe-353c-440b-b446-6538734f4536\n",
            "To: c:\\Users\\luqui\\OneDrive\\lvcas\\USP\\7o Período\\Redes Neurais\\trabalho\\PianoSkillsAssessment\\audio_samples.zip\n",
            "\n",
            "  0%|          | 0.00/777M [00:00<?, ?B/s]\n",
            "  0%|          | 3.15M/777M [00:00<00:25, 30.6MB/s]\n",
            "  1%|▏         | 9.96M/777M [00:00<00:15, 50.5MB/s]\n",
            "  2%|▏         | 16.8M/777M [00:00<00:13, 57.1MB/s]\n",
            "  3%|▎         | 23.6M/777M [00:00<00:12, 59.8MB/s]\n",
            "  4%|▍         | 30.4M/777M [00:00<00:12, 61.4MB/s]\n",
            "  5%|▍         | 37.2M/777M [00:00<00:11, 62.9MB/s]\n",
            "  6%|▌         | 45.6M/777M [00:00<00:10, 66.8MB/s]\n",
            "  7%|▋         | 54.5M/777M [00:00<00:09, 72.8MB/s]\n",
            "  8%|▊         | 62.9M/777M [00:00<00:09, 74.8MB/s]\n",
            "  9%|▉         | 70.8M/777M [00:01<00:09, 75.7MB/s]\n",
            " 10%|█         | 78.6M/777M [00:01<00:09, 73.3MB/s]\n",
            " 11%|█         | 87.0M/777M [00:01<00:09, 74.9MB/s]\n",
            " 12%|█▏        | 95.4M/777M [00:01<00:08, 76.6MB/s]\n",
            " 13%|█▎        | 104M/777M [00:01<00:08, 77.5MB/s] \n",
            " 14%|█▍        | 112M/777M [00:01<00:08, 77.6MB/s]\n",
            " 16%|█▌        | 121M/777M [00:01<00:08, 79.0MB/s]\n",
            " 17%|█▋        | 129M/777M [00:01<00:08, 79.8MB/s]\n",
            " 18%|█▊        | 137M/777M [00:01<00:08, 79.6MB/s]\n",
            " 19%|█▊        | 146M/777M [00:02<00:07, 79.4MB/s]\n",
            " 20%|█▉        | 154M/777M [00:02<00:07, 79.7MB/s]\n",
            " 21%|██        | 163M/777M [00:02<00:07, 79.2MB/s]\n",
            " 22%|██▏       | 171M/777M [00:02<00:07, 79.7MB/s]\n",
            " 23%|██▎       | 179M/777M [00:02<00:07, 77.5MB/s]\n",
            " 24%|██▍       | 187M/777M [00:02<00:07, 77.0MB/s]\n",
            " 25%|██▌       | 196M/777M [00:02<00:07, 78.2MB/s]\n",
            " 26%|██▌       | 204M/777M [00:02<00:07, 78.2MB/s]\n",
            " 27%|██▋       | 212M/777M [00:02<00:07, 77.2MB/s]\n",
            " 28%|██▊       | 220M/777M [00:02<00:07, 77.4MB/s]\n",
            " 29%|██▉       | 228M/777M [00:03<00:07, 77.2MB/s]\n",
            " 30%|███       | 236M/777M [00:03<00:06, 77.7MB/s]\n",
            " 32%|███▏      | 245M/777M [00:03<00:06, 80.1MB/s]\n",
            " 33%|███▎      | 254M/777M [00:03<00:06, 79.4MB/s]\n",
            " 34%|███▎      | 262M/777M [00:03<00:06, 80.4MB/s]\n",
            " 35%|███▍      | 271M/777M [00:03<00:06, 77.0MB/s]\n",
            " 36%|███▌      | 279M/777M [00:03<00:06, 77.5MB/s]\n",
            " 37%|███▋      | 287M/777M [00:03<00:06, 77.2MB/s]\n",
            " 38%|███▊      | 295M/777M [00:03<00:06, 77.0MB/s]\n",
            " 39%|███▉      | 304M/777M [00:04<00:06, 78.1MB/s]\n",
            " 40%|████      | 312M/777M [00:04<00:05, 79.0MB/s]\n",
            " 41%|████      | 320M/777M [00:04<00:05, 77.0MB/s]\n",
            " 42%|████▏     | 329M/777M [00:04<00:05, 78.1MB/s]\n",
            " 43%|████▎     | 337M/777M [00:04<00:05, 78.5MB/s]\n",
            " 44%|████▍     | 345M/777M [00:04<00:05, 78.2MB/s]\n",
            " 45%|████▌     | 353M/777M [00:04<00:05, 77.5MB/s]\n",
            " 46%|████▋     | 361M/777M [00:04<00:05, 78.9MB/s]\n",
            " 48%|████▊     | 370M/777M [00:04<00:05, 78.6MB/s]\n",
            " 49%|████▊     | 378M/777M [00:04<00:05, 75.1MB/s]\n",
            " 50%|████▉     | 386M/777M [00:05<00:05, 73.3MB/s]\n",
            " 51%|█████     | 395M/777M [00:05<00:04, 77.2MB/s]\n",
            " 52%|█████▏    | 403M/777M [00:05<00:04, 76.9MB/s]\n",
            " 53%|█████▎    | 411M/777M [00:05<00:04, 78.1MB/s]\n",
            " 54%|█████▍    | 419M/777M [00:05<00:04, 77.8MB/s]\n",
            " 55%|█████▍    | 427M/777M [00:05<00:04, 79.1MB/s]\n",
            " 56%|█████▌    | 436M/777M [00:05<00:04, 79.2MB/s]\n",
            " 57%|█████▋    | 444M/777M [00:05<00:04, 80.1MB/s]\n",
            " 58%|█████▊    | 452M/777M [00:05<00:04, 77.8MB/s]\n",
            " 59%|█████▉    | 460M/777M [00:06<00:04, 77.5MB/s]\n",
            " 60%|██████    | 468M/777M [00:06<00:03, 77.7MB/s]\n",
            " 61%|██████▏   | 477M/777M [00:06<00:03, 78.9MB/s]\n",
            " 62%|██████▏   | 485M/777M [00:06<00:03, 77.0MB/s]\n",
            " 63%|██████▎   | 493M/777M [00:06<00:03, 76.7MB/s]\n",
            " 65%|██████▍   | 502M/777M [00:06<00:03, 77.9MB/s]\n",
            " 66%|██████▌   | 510M/777M [00:06<00:03, 71.7MB/s]\n",
            " 66%|██████▋   | 517M/777M [00:06<00:04, 61.0MB/s]\n",
            " 67%|██████▋   | 524M/777M [00:07<00:04, 58.4MB/s]\n",
            " 68%|██████▊   | 532M/777M [00:07<00:03, 64.5MB/s]\n",
            " 69%|██████▉   | 539M/777M [00:07<00:03, 61.5MB/s]\n",
            " 70%|███████   | 547M/777M [00:07<00:03, 66.8MB/s]\n",
            " 71%|███████▏  | 555M/777M [00:07<00:03, 69.8MB/s]\n",
            " 72%|███████▏  | 564M/777M [00:07<00:03, 71.2MB/s]\n",
            " 74%|███████▎  | 571M/777M [00:07<00:02, 72.8MB/s]\n",
            " 75%|███████▍  | 579M/777M [00:07<00:02, 74.4MB/s]\n",
            " 76%|███████▌  | 587M/777M [00:07<00:02, 75.2MB/s]\n",
            " 77%|███████▋  | 596M/777M [00:07<00:02, 76.9MB/s]\n",
            " 78%|███████▊  | 604M/777M [00:08<00:02, 78.4MB/s]\n",
            " 79%|███████▉  | 612M/777M [00:08<00:02, 77.8MB/s]\n",
            " 80%|███████▉  | 621M/777M [00:08<00:01, 79.4MB/s]\n",
            " 81%|████████  | 629M/777M [00:08<00:01, 78.9MB/s]\n",
            " 82%|████████▏ | 638M/777M [00:08<00:01, 75.3MB/s]\n",
            " 83%|████████▎ | 646M/777M [00:08<00:01, 77.3MB/s]\n",
            " 84%|████████▍ | 654M/777M [00:08<00:01, 78.5MB/s]\n",
            " 85%|████████▌ | 663M/777M [00:08<00:01, 78.4MB/s]\n",
            " 86%|████████▋ | 671M/777M [00:08<00:01, 78.2MB/s]\n",
            " 87%|████████▋ | 679M/777M [00:09<00:01, 79.3MB/s]\n",
            " 88%|████████▊ | 688M/777M [00:09<00:01, 79.7MB/s]\n",
            " 90%|████████▉ | 696M/777M [00:09<00:01, 79.6MB/s]\n",
            " 91%|█████████ | 705M/777M [00:09<00:00, 77.6MB/s]\n",
            " 92%|█████████▏| 713M/777M [00:09<00:00, 77.5MB/s]\n",
            " 93%|█████████▎| 721M/777M [00:09<00:00, 77.6MB/s]\n",
            " 94%|█████████▍| 729M/777M [00:09<00:00, 78.8MB/s]\n",
            " 95%|█████████▍| 738M/777M [00:09<00:00, 79.9MB/s]\n",
            " 96%|█████████▌| 746M/777M [00:09<00:00, 78.6MB/s]\n",
            " 97%|█████████▋| 754M/777M [00:09<00:00, 79.9MB/s]\n",
            " 98%|█████████▊| 763M/777M [00:10<00:00, 79.3MB/s]\n",
            " 99%|█████████▉| 771M/777M [00:10<00:00, 80.0MB/s]\n",
            "100%|██████████| 777M/777M [00:10<00:00, 75.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 169RiUEtrp4cD1zN-AjEWvSUyGOAcDgXb\n",
        "!gdown 1Be4s_PFa2Uyc67iOqAEyMc_Ce5WiJ_fH\n",
        "!gdown 1fc6DWa9hnxYtRhuHntdXllPrrVQ54NiH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!tar -xf processed_data.zip\n",
        "!tar -xf audio_samples.zip\n",
        "!tar -xf checkpoints_batch4.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fIypxGc_CDKC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from preprocessed_dataset import PreprocessedDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "from dataloader_multimodal import VideoDataset\n",
        "from opts import *\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "N0suy4vv43R7"
      },
      "outputs": [],
      "source": [
        "PROCESSED_TRAIN_DIR = './processed_data/train/'\n",
        "PROCESSED_TEST_DIR = './processed_data/test/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EZ7tQCf4COJq"
      },
      "outputs": [],
      "source": [
        "class AuralSkillClassifier(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        # inicia um backbone da rede com a ResNet18 pré-treinada\n",
        "        self.backbone = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "\n",
        "        # modifica a primeira camada para receber apenas 1 canal de entrada\n",
        "        self.backbone.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "\n",
        "        # remove a camada de classificação original da ResNet, substituindo-a por uma nn.Identity()\n",
        "        self.backbone.fc = nn.Identity()\n",
        "\n",
        "        # cria uma nova camada de classificação, conforme descrita no artigo, com 512 valores de entrada e 128 de saída,\n",
        "        # posteriormente passando por uma camada que faz a classificação de fato, com 10 valores de saída (correspondentes às classes)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(in_features=512, out_features=128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5)\n",
        "        )\n",
        "        self.classification_head = nn.Linear(128, num_classes)\n",
        "        self.regression_head = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.backbone(x) # passa a entrada pela rede ResNet\n",
        "        features_128 = self.classifier(features) # passa o resultado da ResNet pela camada final de classificação\n",
        "        logits_cls = self.classification_head(features_128)\n",
        "        output_reg = self.regression_head(features_128)\n",
        "\n",
        "        return logits_cls, output_reg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_class_weights(dataset, num_classes=10):\n",
        "    \"\"\"\n",
        "    Calcula os pesos para cada classe com base na frequência inversa das amostras.\n",
        "    Esta função percorre o dataset uma vez para contar as ocorrências de cada classe\n",
        "    e depois calcula os pesos.\n",
        "\n",
        "    :param dataset: Uma instância do seu objeto de Dataset (ex: PreprocessedDataset).\n",
        "    :param num_classes: O número total de classes no seu problema.\n",
        "    :return: Um tensor do PyTorch de formato [num_classes] com o peso para cada classe.\n",
        "    \"\"\"\n",
        "    print(\"Iniciando o cálculo dos pesos das classes...\")\n",
        "\n",
        "    # --- PASSO 1: Contar as Amostras de Cada Classe ---\n",
        "    \n",
        "    # A forma mais eficiente de contar é usar um DataLoader para iterar sobre os dados.\n",
        "    # batch_size pode ser maior para acelerar a contagem. shuffle=False não é necessário aqui.\n",
        "    loader = DataLoader(dataset, batch_size=64, shuffle=False, num_workers=4)\n",
        "    \n",
        "    # Usaremos um Counter para armazenar as contagens de cada label.\n",
        "    class_counts = Counter()\n",
        "    \n",
        "    # Itera sobre o dataset para contar os labels\n",
        "    for batch_data in loader:\n",
        "        labels = batch_data['player_lvl']\n",
        "        # .tolist() converte o tensor de labels do lote para uma lista Python\n",
        "        class_counts.update(labels.tolist())\n",
        "\n",
        "    # Transforma o Counter em uma lista ordenada pelo índice da classe (de 0 a 9)\n",
        "    # Se uma classe não aparecer, sua contagem será 0.\n",
        "    counts = [class_counts.get(i, 0) for i in range(num_classes)]\n",
        "    print(f\"Contagem de amostras por classe: {counts}\")\n",
        "    \n",
        "\n",
        "    # --- PASSO 2: Calcular os Pesos ---\n",
        "    \n",
        "    # A fórmula é o inverso da frequência: peso = 1 / contagem\n",
        "    # Usamos uma lista para guardar os pesos calculados.\n",
        "    weights = []\n",
        "    for count in counts:\n",
        "        # Lida com o caso de uma classe não ter amostras para evitar divisão por zero\n",
        "        if count == 0:\n",
        "            weights.append(0.0)\n",
        "        else:\n",
        "            weights.append(1.0 / count)\n",
        "\n",
        "    # Converte a lista de pesos em um tensor do PyTorch do tipo float\n",
        "    weights_tensor = torch.tensor(weights, dtype=torch.float)\n",
        "    \n",
        "    # Opcional, mas recomendado: Normalizar os pesos para que a soma deles não seja muito grande,\n",
        "    # o que poderia desestabilizar o treinamento. Aqui, normalizamos pela soma.\n",
        "    weights_tensor = weights_tensor / weights_tensor.sum()\n",
        "    \n",
        "    print(f\"Pesos calculados para as classes: {weights_tensor}\")\n",
        "    print(\"Cálculo de pesos concluído.\")\n",
        "    \n",
        "    return weights_tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzeEC47MCRfB",
        "outputId": "27af1f83-11ca-425f-9582-2d34b072fdb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Usando o dispositivo: cuda\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Usando o dispositivo: {device}\")\n",
        "\n",
        "# Cria uma instância do modelo e a move para o dispositivo\n",
        "model = AuralSkillClassifier(num_classes=10).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csjQ_ioWCW56",
        "outputId": "5a005adc-bded-4a95-fad9-b4a3a48d53ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset encontrado. Número de amostras: 516\n",
            "Iniciando o cálculo dos pesos das classes...\n",
            "Contagem de amostras por classe: [18, 19, 34, 16, 27, 22, 72, 89, 157, 62]\n",
            "Pesos calculados para as classes: tensor([0.1682, 0.1594, 0.0891, 0.1893, 0.1122, 0.1377, 0.0421, 0.0340, 0.0193,\n",
            "        0.0488])\n",
            "Cálculo de pesos concluído.\n"
          ]
        }
      ],
      "source": [
        "train_dataset = PreprocessedDataset(data_dir=PROCESSED_TRAIN_DIR)\n",
        "pesos_tensor = calculate_class_weights(train_dataset).to(device)\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "criterion_cls = nn.CrossEntropyLoss(weight=pesos_tensor)\n",
        "criterion_reg_l1 = nn.L1Loss()\n",
        "criterion_reg_l2 = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6huA08HbCZjJ",
        "outputId": "664fa393-f548-41af-c247-6d8821943a8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nenhum checkpoint encontrado. Iniciando treinamento do zero.\n",
            "--- Iniciando Época 1/100 ---\n",
            "  Processando lote 1/129\n",
            "  Processando lote 2/129\n",
            "  Processando lote 3/129\n",
            "  Processando lote 4/129\n",
            "  Processando lote 5/129\n",
            "  Processando lote 6/129\n",
            "  Processando lote 7/129\n",
            "  Processando lote 8/129\n",
            "  Processando lote 9/129\n",
            "  Processando lote 10/129\n",
            "  Processando lote 11/129\n",
            "  Processando lote 12/129\n",
            "  Processando lote 13/129\n",
            "  Processando lote 14/129\n",
            "  Processando lote 15/129\n",
            "  Processando lote 16/129\n",
            "  Processando lote 17/129\n",
            "  Processando lote 18/129\n",
            "  Processando lote 19/129\n",
            "  Processando lote 20/129\n",
            "  Processando lote 21/129\n",
            "  Processando lote 22/129\n",
            "  Processando lote 23/129\n",
            "  Processando lote 24/129\n",
            "  Processando lote 25/129\n",
            "  Processando lote 26/129\n",
            "  Processando lote 27/129\n",
            "  Processando lote 28/129\n",
            "  Processando lote 29/129\n",
            "  Processando lote 30/129\n",
            "  Processando lote 31/129\n",
            "  Processando lote 32/129\n",
            "  Processando lote 33/129\n",
            "  Processando lote 34/129\n",
            "  Processando lote 35/129\n",
            "  Processando lote 36/129\n",
            "  Processando lote 37/129\n",
            "  Processando lote 38/129\n",
            "  Processando lote 39/129\n",
            "  Processando lote 40/129\n",
            "  Processando lote 41/129\n",
            "  Processando lote 42/129\n",
            "  Processando lote 43/129\n",
            "  Processando lote 44/129\n",
            "  Processando lote 45/129\n",
            "  Processando lote 46/129\n",
            "  Processando lote 47/129\n",
            "  Processando lote 48/129\n",
            "  Processando lote 49/129\n",
            "  Processando lote 50/129\n",
            "  Processando lote 51/129\n",
            "  Processando lote 52/129\n",
            "  Processando lote 53/129\n",
            "  Processando lote 54/129\n",
            "  Processando lote 55/129\n",
            "  Processando lote 56/129\n",
            "  Processando lote 57/129\n",
            "  Processando lote 58/129\n",
            "  Processando lote 59/129\n",
            "  Processando lote 60/129\n",
            "  Processando lote 61/129\n",
            "  Processando lote 62/129\n",
            "  Processando lote 63/129\n",
            "  Processando lote 64/129\n",
            "  Processando lote 65/129\n",
            "  Processando lote 66/129\n",
            "  Processando lote 67/129\n",
            "  Processando lote 68/129\n",
            "  Processando lote 69/129\n",
            "  Processando lote 70/129\n",
            "  Processando lote 71/129\n",
            "  Processando lote 72/129\n",
            "  Processando lote 73/129\n",
            "  Processando lote 74/129\n",
            "  Processando lote 75/129\n",
            "  Processando lote 76/129\n",
            "  Processando lote 77/129\n",
            "  Processando lote 78/129\n",
            "  Processando lote 79/129\n",
            "  Processando lote 80/129\n",
            "  Processando lote 81/129\n",
            "  Processando lote 82/129\n",
            "  Processando lote 83/129\n",
            "  Processando lote 84/129\n",
            "  Processando lote 85/129\n",
            "  Processando lote 86/129\n",
            "  Processando lote 87/129\n",
            "  Processando lote 88/129\n",
            "  Processando lote 89/129\n",
            "  Processando lote 90/129\n",
            "  Processando lote 91/129\n",
            "  Processando lote 92/129\n",
            "  Processando lote 93/129\n",
            "  Processando lote 94/129\n",
            "  Processando lote 95/129\n",
            "  Processando lote 96/129\n",
            "  Processando lote 97/129\n",
            "  Processando lote 98/129\n",
            "  Processando lote 99/129\n",
            "  Processando lote 100/129\n",
            "  Processando lote 101/129\n",
            "  Processando lote 102/129\n",
            "  Processando lote 103/129\n",
            "  Processando lote 104/129\n",
            "  Processando lote 105/129\n",
            "  Processando lote 106/129\n",
            "  Processando lote 107/129\n",
            "  Processando lote 108/129\n",
            "  Processando lote 109/129\n",
            "  Processando lote 110/129\n",
            "  Processando lote 111/129\n",
            "  Processando lote 112/129\n",
            "  Processando lote 113/129\n",
            "  Processando lote 114/129\n",
            "  Processando lote 115/129\n",
            "  Processando lote 116/129\n",
            "  Processando lote 117/129\n",
            "  Processando lote 118/129\n",
            "  Processando lote 119/129\n",
            "  Processando lote 120/129\n",
            "  Processando lote 121/129\n",
            "  Processando lote 122/129\n",
            "  Processando lote 123/129\n",
            "  Processando lote 124/129\n",
            "  Processando lote 125/129\n",
            "  Processando lote 126/129\n",
            "  Processando lote 127/129\n",
            "  Processando lote 128/129\n",
            "  Processando lote 129/129\n",
            "--- Fim da Época 1. Salvando checkpoint... ---\n",
            "Checkpoint salvo em: ./checkpoints_batch4_weight_decay/model_epoch_1.pt\n",
            "--- Iniciando Época 2/100 ---\n",
            "  Processando lote 1/129\n",
            "  Processando lote 2/129\n",
            "  Processando lote 3/129\n",
            "  Processando lote 4/129\n",
            "  Processando lote 5/129\n",
            "  Processando lote 6/129\n",
            "  Processando lote 7/129\n",
            "  Processando lote 8/129\n",
            "  Processando lote 9/129\n",
            "  Processando lote 10/129\n",
            "  Processando lote 11/129\n",
            "  Processando lote 12/129\n",
            "  Processando lote 13/129\n",
            "  Processando lote 14/129\n",
            "  Processando lote 15/129\n",
            "  Processando lote 16/129\n",
            "  Processando lote 17/129\n",
            "  Processando lote 18/129\n",
            "  Processando lote 19/129\n",
            "  Processando lote 20/129\n",
            "  Processando lote 21/129\n",
            "  Processando lote 22/129\n",
            "  Processando lote 23/129\n",
            "  Processando lote 24/129\n",
            "  Processando lote 25/129\n",
            "  Processando lote 26/129\n",
            "  Processando lote 27/129\n",
            "  Processando lote 28/129\n",
            "  Processando lote 29/129\n",
            "  Processando lote 30/129\n",
            "  Processando lote 31/129\n",
            "  Processando lote 32/129\n",
            "  Processando lote 33/129\n",
            "  Processando lote 34/129\n",
            "  Processando lote 35/129\n",
            "  Processando lote 36/129\n",
            "  Processando lote 37/129\n",
            "  Processando lote 38/129\n",
            "  Processando lote 39/129\n",
            "  Processando lote 40/129\n",
            "  Processando lote 41/129\n",
            "  Processando lote 42/129\n",
            "  Processando lote 43/129\n",
            "  Processando lote 44/129\n",
            "  Processando lote 45/129\n",
            "  Processando lote 46/129\n",
            "  Processando lote 47/129\n",
            "  Processando lote 48/129\n",
            "  Processando lote 49/129\n",
            "  Processando lote 50/129\n",
            "  Processando lote 51/129\n",
            "  Processando lote 52/129\n",
            "  Processando lote 53/129\n",
            "  Processando lote 54/129\n",
            "  Processando lote 55/129\n",
            "  Processando lote 56/129\n",
            "  Processando lote 57/129\n",
            "  Processando lote 58/129\n",
            "  Processando lote 59/129\n",
            "  Processando lote 60/129\n",
            "  Processando lote 61/129\n",
            "  Processando lote 62/129\n",
            "  Processando lote 63/129\n",
            "  Processando lote 64/129\n",
            "  Processando lote 65/129\n",
            "  Processando lote 66/129\n",
            "  Processando lote 67/129\n",
            "  Processando lote 68/129\n",
            "  Processando lote 69/129\n",
            "  Processando lote 70/129\n",
            "  Processando lote 71/129\n",
            "  Processando lote 72/129\n",
            "  Processando lote 73/129\n",
            "  Processando lote 74/129\n",
            "  Processando lote 75/129\n",
            "  Processando lote 76/129\n",
            "  Processando lote 77/129\n",
            "  Processando lote 78/129\n",
            "  Processando lote 79/129\n",
            "  Processando lote 80/129\n",
            "  Processando lote 81/129\n",
            "  Processando lote 82/129\n",
            "  Processando lote 83/129\n",
            "  Processando lote 84/129\n",
            "  Processando lote 85/129\n",
            "  Processando lote 86/129\n",
            "  Processando lote 87/129\n",
            "  Processando lote 88/129\n",
            "  Processando lote 89/129\n",
            "  Processando lote 90/129\n",
            "  Processando lote 91/129\n",
            "  Processando lote 92/129\n",
            "  Processando lote 93/129\n",
            "  Processando lote 94/129\n",
            "  Processando lote 95/129\n",
            "  Processando lote 96/129\n",
            "  Processando lote 97/129\n",
            "  Processando lote 98/129\n",
            "  Processando lote 99/129\n",
            "  Processando lote 100/129\n",
            "  Processando lote 101/129\n",
            "  Processando lote 102/129\n",
            "  Processando lote 103/129\n",
            "  Processando lote 104/129\n",
            "  Processando lote 105/129\n",
            "  Processando lote 106/129\n",
            "  Processando lote 107/129\n",
            "  Processando lote 108/129\n",
            "  Processando lote 109/129\n",
            "  Processando lote 110/129\n",
            "  Processando lote 111/129\n",
            "  Processando lote 112/129\n",
            "  Processando lote 113/129\n",
            "  Processando lote 114/129\n",
            "  Processando lote 115/129\n",
            "  Processando lote 116/129\n",
            "  Processando lote 117/129\n",
            "  Processando lote 118/129\n",
            "  Processando lote 119/129\n",
            "  Processando lote 120/129\n",
            "  Processando lote 121/129\n",
            "  Processando lote 122/129\n",
            "  Processando lote 123/129\n",
            "  Processando lote 124/129\n",
            "  Processando lote 125/129\n",
            "  Processando lote 126/129\n",
            "  Processando lote 127/129\n",
            "  Processando lote 128/129\n",
            "  Processando lote 129/129\n",
            "--- Fim da Época 2. Salvando checkpoint... ---\n",
            "Checkpoint salvo em: ./checkpoints_batch4_weight_decay/model_epoch_2.pt\n",
            "--- Iniciando Época 3/100 ---\n",
            "  Processando lote 1/129\n",
            "  Processando lote 2/129\n",
            "  Processando lote 3/129\n",
            "  Processando lote 4/129\n",
            "  Processando lote 5/129\n",
            "  Processando lote 6/129\n",
            "  Processando lote 7/129\n",
            "  Processando lote 8/129\n",
            "  Processando lote 9/129\n",
            "  Processando lote 10/129\n",
            "  Processando lote 11/129\n",
            "  Processando lote 12/129\n",
            "  Processando lote 13/129\n",
            "  Processando lote 14/129\n",
            "  Processando lote 15/129\n",
            "  Processando lote 16/129\n",
            "  Processando lote 17/129\n",
            "  Processando lote 18/129\n",
            "  Processando lote 19/129\n",
            "  Processando lote 20/129\n",
            "  Processando lote 21/129\n",
            "  Processando lote 22/129\n",
            "  Processando lote 23/129\n",
            "  Processando lote 24/129\n",
            "  Processando lote 25/129\n",
            "  Processando lote 26/129\n",
            "  Processando lote 27/129\n",
            "  Processando lote 28/129\n",
            "  Processando lote 29/129\n",
            "  Processando lote 30/129\n",
            "  Processando lote 31/129\n",
            "  Processando lote 32/129\n",
            "  Processando lote 33/129\n",
            "  Processando lote 34/129\n",
            "  Processando lote 35/129\n",
            "  Processando lote 36/129\n",
            "  Processando lote 37/129\n",
            "  Processando lote 38/129\n",
            "  Processando lote 39/129\n",
            "  Processando lote 40/129\n",
            "  Processando lote 41/129\n",
            "  Processando lote 42/129\n",
            "  Processando lote 43/129\n",
            "  Processando lote 44/129\n",
            "  Processando lote 45/129\n",
            "  Processando lote 46/129\n",
            "  Processando lote 47/129\n",
            "  Processando lote 48/129\n",
            "  Processando lote 49/129\n",
            "  Processando lote 50/129\n",
            "  Processando lote 51/129\n",
            "  Processando lote 52/129\n",
            "  Processando lote 53/129\n",
            "  Processando lote 54/129\n",
            "  Processando lote 55/129\n",
            "  Processando lote 56/129\n",
            "  Processando lote 57/129\n",
            "  Processando lote 58/129\n",
            "  Processando lote 59/129\n",
            "  Processando lote 60/129\n",
            "  Processando lote 61/129\n",
            "  Processando lote 62/129\n",
            "  Processando lote 63/129\n",
            "  Processando lote 64/129\n",
            "  Processando lote 65/129\n",
            "  Processando lote 66/129\n",
            "  Processando lote 67/129\n",
            "  Processando lote 68/129\n",
            "  Processando lote 69/129\n",
            "  Processando lote 70/129\n",
            "  Processando lote 71/129\n",
            "  Processando lote 72/129\n",
            "  Processando lote 73/129\n",
            "  Processando lote 74/129\n",
            "  Processando lote 75/129\n",
            "  Processando lote 76/129\n",
            "  Processando lote 77/129\n",
            "  Processando lote 78/129\n",
            "  Processando lote 79/129\n",
            "  Processando lote 80/129\n",
            "  Processando lote 81/129\n",
            "  Processando lote 82/129\n",
            "  Processando lote 83/129\n",
            "  Processando lote 84/129\n",
            "  Processando lote 85/129\n",
            "  Processando lote 86/129\n",
            "  Processando lote 87/129\n",
            "  Processando lote 88/129\n",
            "  Processando lote 89/129\n",
            "  Processando lote 90/129\n",
            "  Processando lote 91/129\n",
            "  Processando lote 92/129\n",
            "  Processando lote 93/129\n",
            "  Processando lote 94/129\n",
            "  Processando lote 95/129\n",
            "  Processando lote 96/129\n",
            "  Processando lote 97/129\n",
            "  Processando lote 98/129\n",
            "  Processando lote 99/129\n",
            "  Processando lote 100/129\n",
            "  Processando lote 101/129\n",
            "  Processando lote 102/129\n",
            "  Processando lote 103/129\n",
            "  Processando lote 104/129\n",
            "  Processando lote 105/129\n",
            "  Processando lote 106/129\n",
            "  Processando lote 107/129\n",
            "  Processando lote 108/129\n",
            "  Processando lote 109/129\n",
            "  Processando lote 110/129\n",
            "  Processando lote 111/129\n",
            "  Processando lote 112/129\n",
            "  Processando lote 113/129\n",
            "  Processando lote 114/129\n",
            "  Processando lote 115/129\n",
            "  Processando lote 116/129\n",
            "  Processando lote 117/129\n",
            "  Processando lote 118/129\n",
            "  Processando lote 119/129\n",
            "  Processando lote 120/129\n",
            "  Processando lote 121/129\n",
            "  Processando lote 122/129\n",
            "  Processando lote 123/129\n",
            "  Processando lote 124/129\n",
            "  Processando lote 125/129\n",
            "  Processando lote 126/129\n",
            "  Processando lote 127/129\n",
            "  Processando lote 128/129\n",
            "  Processando lote 129/129\n",
            "--- Fim da Época 3. Salvando checkpoint... ---\n",
            "Checkpoint salvo em: ./checkpoints_batch4_weight_decay/model_epoch_3.pt\n",
            "--- Iniciando Época 4/100 ---\n",
            "  Processando lote 1/129\n",
            "  Processando lote 2/129\n",
            "  Processando lote 3/129\n",
            "  Processando lote 4/129\n",
            "  Processando lote 5/129\n",
            "  Processando lote 6/129\n",
            "  Processando lote 7/129\n",
            "  Processando lote 8/129\n",
            "  Processando lote 9/129\n",
            "  Processando lote 10/129\n",
            "  Processando lote 11/129\n",
            "  Processando lote 12/129\n",
            "  Processando lote 13/129\n",
            "  Processando lote 14/129\n",
            "  Processando lote 15/129\n",
            "  Processando lote 16/129\n",
            "  Processando lote 17/129\n",
            "  Processando lote 18/129\n",
            "  Processando lote 19/129\n",
            "  Processando lote 20/129\n",
            "  Processando lote 21/129\n",
            "  Processando lote 22/129\n",
            "  Processando lote 23/129\n",
            "  Processando lote 24/129\n",
            "  Processando lote 25/129\n",
            "  Processando lote 26/129\n",
            "  Processando lote 27/129\n",
            "  Processando lote 28/129\n",
            "  Processando lote 29/129\n",
            "  Processando lote 30/129\n",
            "  Processando lote 31/129\n",
            "  Processando lote 32/129\n",
            "  Processando lote 33/129\n",
            "  Processando lote 34/129\n",
            "  Processando lote 35/129\n",
            "  Processando lote 36/129\n",
            "  Processando lote 37/129\n",
            "  Processando lote 38/129\n",
            "  Processando lote 39/129\n",
            "  Processando lote 40/129\n",
            "  Processando lote 41/129\n",
            "  Processando lote 42/129\n",
            "  Processando lote 43/129\n",
            "  Processando lote 44/129\n",
            "  Processando lote 45/129\n",
            "  Processando lote 46/129\n",
            "  Processando lote 47/129\n",
            "  Processando lote 48/129\n",
            "  Processando lote 49/129\n",
            "  Processando lote 50/129\n",
            "  Processando lote 51/129\n",
            "  Processando lote 52/129\n",
            "  Processando lote 53/129\n",
            "  Processando lote 54/129\n",
            "  Processando lote 55/129\n",
            "  Processando lote 56/129\n",
            "  Processando lote 57/129\n",
            "  Processando lote 58/129\n",
            "  Processando lote 59/129\n",
            "  Processando lote 60/129\n",
            "  Processando lote 61/129\n",
            "  Processando lote 62/129\n",
            "  Processando lote 63/129\n",
            "  Processando lote 64/129\n",
            "  Processando lote 65/129\n",
            "  Processando lote 66/129\n",
            "  Processando lote 67/129\n",
            "  Processando lote 68/129\n",
            "  Processando lote 69/129\n",
            "  Processando lote 70/129\n",
            "  Processando lote 71/129\n",
            "  Processando lote 72/129\n",
            "  Processando lote 73/129\n",
            "  Processando lote 74/129\n",
            "  Processando lote 75/129\n",
            "  Processando lote 76/129\n",
            "  Processando lote 77/129\n",
            "  Processando lote 78/129\n",
            "  Processando lote 79/129\n",
            "  Processando lote 80/129\n",
            "  Processando lote 81/129\n",
            "  Processando lote 82/129\n",
            "  Processando lote 83/129\n",
            "  Processando lote 84/129\n",
            "  Processando lote 85/129\n",
            "  Processando lote 86/129\n",
            "  Processando lote 87/129\n",
            "  Processando lote 88/129\n",
            "  Processando lote 89/129\n",
            "  Processando lote 90/129\n",
            "  Processando lote 91/129\n",
            "  Processando lote 92/129\n",
            "  Processando lote 93/129\n",
            "  Processando lote 94/129\n",
            "  Processando lote 95/129\n",
            "  Processando lote 96/129\n",
            "  Processando lote 97/129\n",
            "  Processando lote 98/129\n",
            "  Processando lote 99/129\n",
            "  Processando lote 100/129\n",
            "  Processando lote 101/129\n",
            "  Processando lote 102/129\n",
            "  Processando lote 103/129\n",
            "  Processando lote 104/129\n",
            "  Processando lote 105/129\n",
            "  Processando lote 106/129\n",
            "  Processando lote 107/129\n",
            "  Processando lote 108/129\n",
            "  Processando lote 109/129\n",
            "  Processando lote 110/129\n",
            "  Processando lote 111/129\n",
            "  Processando lote 112/129\n",
            "  Processando lote 113/129\n",
            "  Processando lote 114/129\n",
            "  Processando lote 115/129\n",
            "  Processando lote 116/129\n",
            "  Processando lote 117/129\n",
            "  Processando lote 118/129\n",
            "  Processando lote 119/129\n",
            "  Processando lote 120/129\n",
            "  Processando lote 121/129\n",
            "  Processando lote 122/129\n",
            "  Processando lote 123/129\n",
            "  Processando lote 124/129\n",
            "  Processando lote 125/129\n",
            "  Processando lote 126/129\n",
            "  Processando lote 127/129\n",
            "  Processando lote 128/129\n",
            "  Processando lote 129/129\n",
            "--- Fim da Época 4. Salvando checkpoint... ---\n",
            "Checkpoint salvo em: ./checkpoints_batch4_weight_decay/model_epoch_4.pt\n",
            "--- Iniciando Época 5/100 ---\n",
            "  Processando lote 1/129\n",
            "  Processando lote 2/129\n",
            "  Processando lote 3/129\n",
            "  Processando lote 4/129\n",
            "  Processando lote 5/129\n",
            "  Processando lote 6/129\n",
            "  Processando lote 7/129\n",
            "  Processando lote 8/129\n",
            "  Processando lote 9/129\n",
            "  Processando lote 10/129\n",
            "  Processando lote 11/129\n",
            "  Processando lote 12/129\n",
            "  Processando lote 13/129\n",
            "  Processando lote 14/129\n",
            "  Processando lote 15/129\n",
            "  Processando lote 16/129\n",
            "  Processando lote 17/129\n",
            "  Processando lote 18/129\n",
            "  Processando lote 19/129\n",
            "  Processando lote 20/129\n",
            "  Processando lote 21/129\n",
            "  Processando lote 22/129\n",
            "  Processando lote 23/129\n",
            "  Processando lote 24/129\n",
            "  Processando lote 25/129\n",
            "  Processando lote 26/129\n",
            "  Processando lote 27/129\n",
            "  Processando lote 28/129\n",
            "  Processando lote 29/129\n",
            "  Processando lote 30/129\n",
            "  Processando lote 31/129\n",
            "  Processando lote 32/129\n",
            "  Processando lote 33/129\n",
            "  Processando lote 34/129\n",
            "  Processando lote 35/129\n",
            "  Processando lote 36/129\n",
            "  Processando lote 37/129\n",
            "  Processando lote 38/129\n",
            "  Processando lote 39/129\n",
            "  Processando lote 40/129\n",
            "  Processando lote 41/129\n",
            "  Processando lote 42/129\n",
            "  Processando lote 43/129\n",
            "  Processando lote 44/129\n",
            "  Processando lote 45/129\n",
            "  Processando lote 46/129\n",
            "  Processando lote 47/129\n",
            "  Processando lote 48/129\n",
            "  Processando lote 49/129\n",
            "  Processando lote 50/129\n",
            "  Processando lote 51/129\n",
            "  Processando lote 52/129\n",
            "  Processando lote 53/129\n",
            "  Processando lote 54/129\n",
            "  Processando lote 55/129\n",
            "  Processando lote 56/129\n",
            "  Processando lote 57/129\n",
            "  Processando lote 58/129\n",
            "  Processando lote 59/129\n",
            "  Processando lote 60/129\n",
            "  Processando lote 61/129\n",
            "  Processando lote 62/129\n",
            "  Processando lote 63/129\n",
            "  Processando lote 64/129\n",
            "  Processando lote 65/129\n",
            "  Processando lote 66/129\n",
            "  Processando lote 67/129\n",
            "  Processando lote 68/129\n",
            "  Processando lote 69/129\n",
            "  Processando lote 70/129\n",
            "  Processando lote 71/129\n",
            "  Processando lote 72/129\n",
            "  Processando lote 73/129\n",
            "  Processando lote 74/129\n",
            "  Processando lote 75/129\n",
            "  Processando lote 76/129\n",
            "  Processando lote 77/129\n",
            "  Processando lote 78/129\n",
            "  Processando lote 79/129\n",
            "  Processando lote 80/129\n",
            "  Processando lote 81/129\n",
            "  Processando lote 82/129\n",
            "  Processando lote 83/129\n",
            "  Processando lote 84/129\n",
            "  Processando lote 85/129\n",
            "  Processando lote 86/129\n",
            "  Processando lote 87/129\n",
            "  Processando lote 88/129\n",
            "  Processando lote 89/129\n",
            "  Processando lote 90/129\n",
            "  Processando lote 91/129\n",
            "  Processando lote 92/129\n",
            "  Processando lote 93/129\n",
            "  Processando lote 94/129\n",
            "  Processando lote 95/129\n",
            "  Processando lote 96/129\n",
            "  Processando lote 97/129\n",
            "  Processando lote 98/129\n",
            "  Processando lote 99/129\n",
            "  Processando lote 100/129\n",
            "  Processando lote 101/129\n",
            "  Processando lote 102/129\n",
            "  Processando lote 103/129\n",
            "  Processando lote 104/129\n",
            "  Processando lote 105/129\n",
            "  Processando lote 106/129\n",
            "  Processando lote 107/129\n",
            "  Processando lote 108/129\n",
            "  Processando lote 109/129\n",
            "  Processando lote 110/129\n",
            "  Processando lote 111/129\n",
            "  Processando lote 112/129\n",
            "  Processando lote 113/129\n",
            "  Processando lote 114/129\n",
            "  Processando lote 115/129\n",
            "  Processando lote 116/129\n",
            "  Processando lote 117/129\n",
            "  Processando lote 118/129\n",
            "  Processando lote 119/129\n",
            "  Processando lote 120/129\n",
            "  Processando lote 121/129\n",
            "  Processando lote 122/129\n",
            "  Processando lote 123/129\n",
            "  Processando lote 124/129\n",
            "  Processando lote 125/129\n",
            "  Processando lote 126/129\n",
            "  Processando lote 127/129\n",
            "  Processando lote 128/129\n",
            "  Processando lote 129/129\n",
            "--- Fim da Época 5. Salvando checkpoint... ---\n",
            "Checkpoint salvo em: ./checkpoints_batch4_weight_decay/model_epoch_5.pt\n",
            "--- Iniciando Época 6/100 ---\n",
            "  Processando lote 1/129\n",
            "  Processando lote 2/129\n",
            "  Processando lote 3/129\n",
            "  Processando lote 4/129\n",
            "  Processando lote 5/129\n",
            "  Processando lote 6/129\n",
            "  Processando lote 7/129\n",
            "  Processando lote 8/129\n",
            "  Processando lote 9/129\n",
            "  Processando lote 10/129\n",
            "  Processando lote 11/129\n",
            "  Processando lote 12/129\n",
            "  Processando lote 13/129\n",
            "  Processando lote 14/129\n",
            "  Processando lote 15/129\n",
            "  Processando lote 16/129\n",
            "  Processando lote 17/129\n",
            "  Processando lote 18/129\n",
            "  Processando lote 19/129\n",
            "  Processando lote 20/129\n",
            "  Processando lote 21/129\n",
            "  Processando lote 22/129\n",
            "  Processando lote 23/129\n",
            "  Processando lote 24/129\n",
            "  Processando lote 25/129\n",
            "  Processando lote 26/129\n",
            "  Processando lote 27/129\n",
            "  Processando lote 28/129\n",
            "  Processando lote 29/129\n",
            "  Processando lote 30/129\n",
            "  Processando lote 31/129\n",
            "  Processando lote 32/129\n",
            "  Processando lote 33/129\n",
            "  Processando lote 34/129\n",
            "  Processando lote 35/129\n",
            "  Processando lote 36/129\n",
            "  Processando lote 37/129\n",
            "  Processando lote 38/129\n",
            "  Processando lote 39/129\n",
            "  Processando lote 40/129\n",
            "  Processando lote 41/129\n",
            "  Processando lote 42/129\n",
            "  Processando lote 43/129\n",
            "  Processando lote 44/129\n",
            "  Processando lote 45/129\n",
            "  Processando lote 46/129\n",
            "  Processando lote 47/129\n",
            "  Processando lote 48/129\n",
            "  Processando lote 49/129\n",
            "  Processando lote 50/129\n",
            "  Processando lote 51/129\n",
            "  Processando lote 52/129\n",
            "  Processando lote 53/129\n",
            "  Processando lote 54/129\n",
            "  Processando lote 55/129\n",
            "  Processando lote 56/129\n",
            "  Processando lote 57/129\n",
            "  Processando lote 58/129\n",
            "  Processando lote 59/129\n",
            "  Processando lote 60/129\n",
            "  Processando lote 61/129\n",
            "  Processando lote 62/129\n",
            "  Processando lote 63/129\n",
            "  Processando lote 64/129\n",
            "  Processando lote 65/129\n",
            "  Processando lote 66/129\n",
            "  Processando lote 67/129\n",
            "  Processando lote 68/129\n",
            "  Processando lote 69/129\n",
            "  Processando lote 70/129\n",
            "  Processando lote 71/129\n",
            "  Processando lote 72/129\n",
            "  Processando lote 73/129\n",
            "  Processando lote 74/129\n",
            "  Processando lote 75/129\n",
            "  Processando lote 76/129\n",
            "  Processando lote 77/129\n",
            "  Processando lote 78/129\n",
            "  Processando lote 79/129\n",
            "  Processando lote 80/129\n",
            "  Processando lote 81/129\n",
            "  Processando lote 82/129\n",
            "  Processando lote 83/129\n",
            "  Processando lote 84/129\n",
            "  Processando lote 85/129\n",
            "  Processando lote 86/129\n",
            "  Processando lote 87/129\n",
            "  Processando lote 88/129\n",
            "  Processando lote 89/129\n",
            "  Processando lote 90/129\n",
            "  Processando lote 91/129\n",
            "  Processando lote 92/129\n",
            "  Processando lote 93/129\n",
            "  Processando lote 94/129\n",
            "  Processando lote 95/129\n",
            "  Processando lote 96/129\n",
            "  Processando lote 97/129\n",
            "  Processando lote 98/129\n",
            "  Processando lote 99/129\n",
            "  Processando lote 100/129\n",
            "  Processando lote 101/129\n",
            "  Processando lote 102/129\n",
            "  Processando lote 103/129\n",
            "  Processando lote 104/129\n",
            "  Processando lote 105/129\n",
            "  Processando lote 106/129\n",
            "  Processando lote 107/129\n",
            "  Processando lote 108/129\n",
            "  Processando lote 109/129\n",
            "  Processando lote 110/129\n",
            "  Processando lote 111/129\n",
            "  Processando lote 112/129\n",
            "  Processando lote 113/129\n",
            "  Processando lote 114/129\n",
            "  Processando lote 115/129\n",
            "  Processando lote 116/129\n",
            "  Processando lote 117/129\n",
            "  Processando lote 118/129\n",
            "  Processando lote 119/129\n",
            "  Processando lote 120/129\n",
            "  Processando lote 121/129\n",
            "  Processando lote 122/129\n",
            "  Processando lote 123/129\n",
            "  Processando lote 124/129\n",
            "  Processando lote 125/129\n",
            "  Processando lote 126/129\n",
            "  Processando lote 127/129\n",
            "  Processando lote 128/129\n",
            "  Processando lote 129/129\n",
            "--- Fim da Época 6. Salvando checkpoint... ---\n",
            "Checkpoint salvo em: ./checkpoints_batch4_weight_decay/model_epoch_6.pt\n",
            "--- Iniciando Época 7/100 ---\n",
            "  Processando lote 1/129\n",
            "  Processando lote 2/129\n",
            "  Processando lote 3/129\n",
            "  Processando lote 4/129\n",
            "  Processando lote 5/129\n",
            "  Processando lote 6/129\n",
            "  Processando lote 7/129\n",
            "  Processando lote 8/129\n",
            "  Processando lote 9/129\n",
            "  Processando lote 10/129\n",
            "  Processando lote 11/129\n",
            "  Processando lote 12/129\n",
            "  Processando lote 13/129\n",
            "  Processando lote 14/129\n",
            "  Processando lote 15/129\n",
            "  Processando lote 16/129\n",
            "  Processando lote 17/129\n",
            "  Processando lote 18/129\n",
            "  Processando lote 19/129\n",
            "  Processando lote 20/129\n",
            "  Processando lote 21/129\n",
            "  Processando lote 22/129\n",
            "  Processando lote 23/129\n",
            "  Processando lote 24/129\n",
            "  Processando lote 25/129\n",
            "  Processando lote 26/129\n",
            "  Processando lote 27/129\n",
            "  Processando lote 28/129\n",
            "  Processando lote 29/129\n",
            "  Processando lote 30/129\n",
            "  Processando lote 31/129\n",
            "  Processando lote 32/129\n",
            "  Processando lote 33/129\n",
            "  Processando lote 34/129\n",
            "  Processando lote 35/129\n",
            "  Processando lote 36/129\n",
            "  Processando lote 37/129\n",
            "  Processando lote 38/129\n",
            "  Processando lote 39/129\n",
            "  Processando lote 40/129\n",
            "  Processando lote 41/129\n",
            "  Processando lote 42/129\n",
            "  Processando lote 43/129\n",
            "  Processando lote 44/129\n",
            "  Processando lote 45/129\n",
            "  Processando lote 46/129\n",
            "  Processando lote 47/129\n",
            "  Processando lote 48/129\n",
            "  Processando lote 49/129\n",
            "  Processando lote 50/129\n",
            "  Processando lote 51/129\n",
            "  Processando lote 52/129\n",
            "  Processando lote 53/129\n",
            "  Processando lote 54/129\n",
            "  Processando lote 55/129\n",
            "  Processando lote 56/129\n",
            "  Processando lote 57/129\n",
            "  Processando lote 58/129\n",
            "  Processando lote 59/129\n",
            "  Processando lote 60/129\n",
            "  Processando lote 61/129\n",
            "  Processando lote 62/129\n",
            "  Processando lote 63/129\n",
            "  Processando lote 64/129\n",
            "  Processando lote 65/129\n",
            "  Processando lote 66/129\n",
            "  Processando lote 67/129\n",
            "  Processando lote 68/129\n",
            "  Processando lote 69/129\n",
            "  Processando lote 70/129\n",
            "  Processando lote 71/129\n",
            "  Processando lote 72/129\n",
            "  Processando lote 73/129\n",
            "  Processando lote 74/129\n",
            "  Processando lote 75/129\n",
            "  Processando lote 76/129\n",
            "  Processando lote 77/129\n",
            "  Processando lote 78/129\n",
            "  Processando lote 79/129\n",
            "  Processando lote 80/129\n",
            "  Processando lote 81/129\n",
            "  Processando lote 82/129\n",
            "  Processando lote 83/129\n",
            "  Processando lote 84/129\n",
            "  Processando lote 85/129\n",
            "  Processando lote 86/129\n",
            "  Processando lote 87/129\n",
            "  Processando lote 88/129\n",
            "  Processando lote 89/129\n",
            "  Processando lote 90/129\n",
            "  Processando lote 91/129\n",
            "  Processando lote 92/129\n",
            "  Processando lote 93/129\n",
            "  Processando lote 94/129\n",
            "  Processando lote 95/129\n",
            "  Processando lote 96/129\n",
            "  Processando lote 97/129\n",
            "  Processando lote 98/129\n",
            "  Processando lote 99/129\n",
            "  Processando lote 100/129\n",
            "  Processando lote 101/129\n",
            "  Processando lote 102/129\n",
            "  Processando lote 103/129\n",
            "  Processando lote 104/129\n",
            "  Processando lote 105/129\n",
            "  Processando lote 106/129\n",
            "  Processando lote 107/129\n",
            "  Processando lote 108/129\n",
            "  Processando lote 109/129\n",
            "  Processando lote 110/129\n",
            "  Processando lote 111/129\n",
            "  Processando lote 112/129\n",
            "  Processando lote 113/129\n",
            "  Processando lote 114/129\n",
            "  Processando lote 115/129\n",
            "  Processando lote 116/129\n",
            "  Processando lote 117/129\n",
            "  Processando lote 118/129\n",
            "  Processando lote 119/129\n",
            "  Processando lote 120/129\n",
            "  Processando lote 121/129\n",
            "  Processando lote 122/129\n",
            "  Processando lote 123/129\n",
            "  Processando lote 124/129\n",
            "  Processando lote 125/129\n",
            "  Processando lote 126/129\n",
            "  Processando lote 127/129\n",
            "  Processando lote 128/129\n",
            "  Processando lote 129/129\n",
            "--- Fim da Época 7. Salvando checkpoint... ---\n",
            "Checkpoint salvo em: ./checkpoints_batch4_weight_decay/model_epoch_7.pt\n",
            "--- Iniciando Época 8/100 ---\n",
            "  Processando lote 1/129\n",
            "  Processando lote 2/129\n",
            "  Processando lote 3/129\n",
            "  Processando lote 4/129\n",
            "  Processando lote 5/129\n",
            "  Processando lote 6/129\n",
            "  Processando lote 7/129\n",
            "  Processando lote 8/129\n",
            "  Processando lote 9/129\n",
            "  Processando lote 10/129\n",
            "  Processando lote 11/129\n",
            "  Processando lote 12/129\n",
            "  Processando lote 13/129\n",
            "  Processando lote 14/129\n",
            "  Processando lote 15/129\n",
            "  Processando lote 16/129\n",
            "  Processando lote 17/129\n",
            "  Processando lote 18/129\n",
            "  Processando lote 19/129\n",
            "  Processando lote 20/129\n",
            "  Processando lote 21/129\n",
            "  Processando lote 22/129\n",
            "  Processando lote 23/129\n",
            "  Processando lote 24/129\n",
            "  Processando lote 25/129\n",
            "  Processando lote 26/129\n",
            "  Processando lote 27/129\n",
            "  Processando lote 28/129\n",
            "  Processando lote 29/129\n",
            "  Processando lote 30/129\n",
            "  Processando lote 31/129\n",
            "  Processando lote 32/129\n",
            "  Processando lote 33/129\n",
            "  Processando lote 34/129\n",
            "  Processando lote 35/129\n",
            "  Processando lote 36/129\n",
            "  Processando lote 37/129\n",
            "  Processando lote 38/129\n",
            "  Processando lote 39/129\n",
            "  Processando lote 40/129\n",
            "  Processando lote 41/129\n",
            "  Processando lote 42/129\n",
            "  Processando lote 43/129\n",
            "  Processando lote 44/129\n",
            "  Processando lote 45/129\n",
            "  Processando lote 46/129\n",
            "  Processando lote 47/129\n",
            "  Processando lote 48/129\n",
            "  Processando lote 49/129\n",
            "  Processando lote 50/129\n",
            "  Processando lote 51/129\n",
            "  Processando lote 52/129\n",
            "  Processando lote 53/129\n",
            "  Processando lote 54/129\n",
            "  Processando lote 55/129\n",
            "  Processando lote 56/129\n",
            "  Processando lote 57/129\n",
            "  Processando lote 58/129\n",
            "  Processando lote 59/129\n",
            "  Processando lote 60/129\n",
            "  Processando lote 61/129\n",
            "  Processando lote 62/129\n",
            "  Processando lote 63/129\n",
            "  Processando lote 64/129\n",
            "  Processando lote 65/129\n",
            "  Processando lote 66/129\n",
            "  Processando lote 67/129\n",
            "  Processando lote 68/129\n",
            "  Processando lote 69/129\n",
            "  Processando lote 70/129\n",
            "  Processando lote 71/129\n",
            "  Processando lote 72/129\n",
            "  Processando lote 73/129\n",
            "  Processando lote 74/129\n",
            "  Processando lote 75/129\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[26], line 67\u001b[0m\n\u001b[0;32m     64\u001b[0m     loss \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m*\u001b[39m loss_cls) \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m0.1\u001b[39m \u001b[38;5;241m*\u001b[39m loss_reg)\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# --- Bloco de Salvamento ao Final de Cada Época ---\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\luqui\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    647\u001b[0m     )\n\u001b[1;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\luqui\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\luqui\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Caminho para o modelo pré-treinado\n",
        "checkpoint_dir = './checkpoints_batch4_weight_decay/'\n",
        "checkpoint_path = './chechpoints_batch4_weight_decay/'\n",
        "# checkpoint_path = os.path.join('./checkpoints', 'model_epoch_100.pt')\n",
        "\n",
        "# Tentar carregar o modelo e o otimizador a partir do checkpoint\n",
        "if os.path.exists(checkpoint_path):\n",
        "    print(f\"Checkpoint encontrado. Carregando o modelo pré-treinado de {checkpoint_path}...\")\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    loss = checkpoint['loss']  # Perda final do último lote da época\n",
        "    print(f\"Modelo carregado com sucesso a partir da época {start_epoch}. Continuando o treinamento...\")\n",
        "else:\n",
        "    print(\"Nenhum checkpoint encontrado. Iniciando treinamento do zero.\")\n",
        "    start_epoch = 0  # Começar do início\n",
        "\n",
        "# --- INÍCIO DO TREINAMENTO ---\n",
        "\n",
        "# Coloque o modelo no modo de treinamento\n",
        "model.train()\n",
        "\n",
        "# Número de épocas de treinamento\n",
        "num_epochs = 100\n",
        "\n",
        "for epoch in range(start_epoch, num_epochs):\n",
        "    print(f\"--- Iniciando Época {epoch+1}/{num_epochs} ---\")\n",
        "\n",
        "    # Para cada lote de dados\n",
        "    for i, batch_data in enumerate(train_loader):\n",
        "        print(f\"  Processando lote {i+1}/{len(train_loader)}\")\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        spectrograms_tensor = batch_data['audio'].to(device)\n",
        "        labels = batch_data['player_lvl'].to(device)\n",
        "\n",
        "        lista_outputs_cls = []\n",
        "        lista_outputs_reg = []\n",
        "\n",
        "        labels_long = labels.long()\n",
        "        labels_float = labels.float()\n",
        "\n",
        "        # Processando cada clipe\n",
        "        for i in range(nclips):\n",
        "            clip_tensor = spectrograms_tensor[:, i, :, :, :]\n",
        "            logits_cls_clip, output_reg_clip = model(clip_tensor)\n",
        "            lista_outputs_cls.append(logits_cls_clip)\n",
        "            lista_outputs_reg.append(output_reg_clip)\n",
        "\n",
        "        # Calculando a saída média\n",
        "        logits_cls = torch.stack(lista_outputs_cls).mean(dim=0)\n",
        "        output_reg = torch.stack(lista_outputs_reg).mean(dim=0)\n",
        "\n",
        "        # Calculando a perda\n",
        "        loss_cls = criterion_cls(logits_cls, labels_long)\n",
        "        output_reg = output_reg.squeeze()\n",
        "        l1 = criterion_reg_l1(output_reg, labels_float)\n",
        "        l2 = criterion_reg_l2(output_reg, labels_float)\n",
        "        loss_reg = l1 + l2\n",
        "\n",
        "        # Perda total\n",
        "        loss = (1.0 * loss_cls) + (0.1 * loss_reg)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # --- Bloco de Salvamento ao Final de Cada Época ---\n",
        "    print(f\"--- Fim da Época {epoch+1}. Salvando checkpoint... ---\")\n",
        "\n",
        "    # Crie uma pasta para os checkpoints no seu Drive\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "    # Defina o caminho completo para o arquivo do checkpoint\n",
        "    checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch+1}.pt')\n",
        "\n",
        "    # Crie o dicionário com tudo que você quer salvar\n",
        "    torch.save({\n",
        "        'epoch': epoch + 1,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': loss,  # Salva a perda do último lote da época\n",
        "    }, checkpoint_path)\n",
        "\n",
        "    print(f\"Checkpoint salvo em: {checkpoint_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqsF-c1XFO6l",
        "outputId": "8cba8074-f235-478e-933b-19d03edfd4c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset encontrado. Número de amostras: 476\n",
            "Dataset de teste carregado. Total de amostras: 476\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "========================================\n",
            "--- RESULTADOS DA AVALIAÇÃO NO CONJUNTO DE TESTE ---\n",
            "========================================\n",
            "Accuracy: 60.50%\n",
            "Precision (weighted): 79.26%\n",
            "Recall (weighted): 60.50%\n",
            "F1 Score (weighted): 62.22%\n",
            "Mean Average Error (MAE): 1.14\n",
            "========================================\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# Garante que o modelo está em modo de avaliação (desliga dropout, etc.)\n",
        "model.eval()\n",
        "\n",
        "# Cria o dataset de teste para pegar uma amostra\n",
        "# (Certifique-se que o modo 'test' corresponde ao seu arquivo .pkl de teste)\n",
        "try:\n",
        "    test_dataset = PreprocessedDataset(PROCESSED_TEST_DIR)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, num_workers=4)\n",
        "    print(f\"Dataset de teste carregado. Total de amostras: {len(test_dataset)}\")\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao carregar o dataset de teste: {e}\")\n",
        "    print(\"Verifique se o arquivo 'annotations_unidist_test.pkl' existe na sua pasta de anotações.\")\n",
        "    # Se der erro aqui, pare a execução da célula\n",
        "    raise\n",
        "\n",
        "# Armazenar as previsões e os rótulos verdadeiros\n",
        "all_predictions = []\n",
        "all_true_labels = []\n",
        "cnt = 0\n",
        "# Loop para avaliar todo o dataset de teste\n",
        "for batch_data in test_loader:\n",
        "    cnt += 1\n",
        "    print(cnt)\n",
        "    # Prepara os dados para o modelo\n",
        "    input_tensor = batch_data['audio'].to(device)\n",
        "    true_labels_batch = batch_data['player_lvl']\n",
        "    # input_tensor = batch_data['audio'].unsqueeze(0).to(device)\n",
        "    # true_label = batch_data['player_lvl']\n",
        "\n",
        "    # Bloco de inferência sem cálculo de gradientes para economizar memória e ser mais rápido\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # --- Lógica de inferência para múltiplos clipes (mesma do treino) ---\n",
        "        clip_outputs_cls = []\n",
        "        n_clips_from_tensor = input_tensor.shape[1] # Pega o nclips do próprio tensor\n",
        "\n",
        "        for i in range(n_clips_from_tensor):\n",
        "            # Pega o i-ésimo clipe\n",
        "            clip_tensor = input_tensor[:, i, :, :, :]\n",
        "\n",
        "            # Passa o clipe pelo modelo\n",
        "            logits_cls_clip, _ = model(clip_tensor)\n",
        "\n",
        "            # Guarda a saída de classificação\n",
        "            clip_outputs_cls.append(logits_cls_clip)\n",
        "\n",
        "        # Agrega as saídas dos clipes tirando a média\n",
        "        final_logits = torch.stack(clip_outputs_cls).mean(dim=0)\n",
        "        # --- Fim da lógica de inferência ---\n",
        "\n",
        "        # Converte os logits em probabilidades\n",
        "        probabilities = torch.softmax(final_logits, dim=1)\n",
        "\n",
        "        # Pega a previsão com a maior probabilidade\n",
        "        # predicted_index = torch.argmax(probabilities, dim=1).item()\n",
        "        predicted_index = torch.argmax(probabilities, dim=1)\n",
        "\n",
        "\n",
        "    # Armazena as previsões e os rótulos verdadeiros\n",
        "    all_predictions.extend(predicted_index.cpu().numpy())\n",
        "    all_true_labels.extend(true_labels_batch.cpu().numpy())\n",
        "\n",
        "# --- Cálculo das Métricas ---\n",
        "accuracy = accuracy_score(all_true_labels, all_predictions)\n",
        "precision = precision_score(all_true_labels, all_predictions, average='weighted', zero_division=1)\n",
        "recall = recall_score(all_true_labels, all_predictions, average='weighted', zero_division=1)\n",
        "f1 = f1_score(all_true_labels, all_predictions, average='weighted', zero_division=1)\n",
        "mae = mean_absolute_error(all_true_labels, all_predictions)\n",
        "\n",
        "# Exibe as métricas\n",
        "print(\"=\"*40)\n",
        "print(f\"--- RESULTADOS DA AVALIAÇÃO NO CONJUNTO DE TESTE ---\")\n",
        "print(\"=\"*40)\n",
        "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
        "print(f\"Precision (weighted): {precision*100:.2f}%\")\n",
        "print(f\"Recall (weighted): {recall*100:.2f}%\")\n",
        "print(f\"F1 Score (weighted): {f1*100:.2f}%\")\n",
        "print(f\"Mean Average Error (MAE): {mae:.2f}\")\n",
        "print(\"=\"*40)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
